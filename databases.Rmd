---
title: "Databases"
date: "2015-06-15"
output: html_document
---
### Перевод
### https://cran.r-project.org/web/packages/dplyr/vignettes/databases.html

```{r, echo=FALSE, warning=FALSE, message=FALSE}
setwd("D:/dplyr")
library(dplyr)
```

Наряду с локальными таблицами данных (data frames / data tables), расположенными в памяти, dplyr также работает с удаленными данными на дисках, хранящимися в базах данных. Как правило, если ваши данные помещаются в памяти, то нет никаких преимуществ в использовании базы данных: меньше скорость, больше хлопот. Причиной, по которой вы захотите использовать dplyr с базой данных, может быть то, что ваши данные уже находятся в базе данных (и вы не хотите работать со статичными csv-файлами, которые кто-то для вас создал), или вы имеете так много данных, что они не помещаются в память. В настоящее время dplyr поддерживает три самые популярные базы данных с открытым исходным кодом (SQLite, MySQL и PostgreSQL) и Google BigQuery.

Так как R почти всегда работает с данными в памяти, если у вас есть много данных в базе данных, вы не можете просто поместить их в R. Вместо этого вам придется работать с поднаборами или агрегированными данными, и dplyr стремится сделать это как можно более простым. Если вы работаете с большими данными, то вы также, вероятно, будете нуждаться в поддержке для получения данных в базу данных и для обеспечения наличия правильных индексов для хорошей производительности. dplyr предоставляет несколько простых инструментов, чтобы помочь с этими задачами, но они не могут заменить соответствующего специалиста.

Мотивацией для поддержки баз данных в dplyr является то, что вы никогда не извлекаете правильный поднабор или агрегированные данные из базы данных с первого раза, и обычно нужно переключатся между R и SQL много раз, пока не будет получен идеальный набор данных. Переключаться между языками когнитивно сложно (особенно потому, что R и SQL так опасно похожи друг на друга), так что dplyr позволяет писать код на R, который автоматически переводится в SQL. Целью dplyr не является замена всех функций SQL: это сложно и чревато ошибками. Вместо этого dplyr генерирует только выражения `SELECT` - команды SQL, которые вы пишете чаще всего в качестве аналитика.

Чтобы получить максимальную отдачу от этой главы, вы будете должны быть знакомы с запросами к базам данных SQL с использованием команды `SELECT`. Если вы знакомы с SQL и хотите узнать больше, я думаю, будут полезны материалы [как индексы работают в SQLite](http://www.sqlite.org/queryplanner.html) и [10 простых шагов для полного понимания SQL](http://tech.pro/tutorial/1555/10-easy-steps-to-a-complete-understanding-of-sql) (*ссылка не работает, но эти материалы можно нагуглить; еще пригодится Бен Форта "Освой самостоятельно SQL"  - прим. пер.*).

## Начало работы

Для экспериментов с базами данных проще всего начать с SQLite, поскольку все необходимое включено в пакет R. Вам не нужно устанавливать что-либо еще и иметь дело с настройкой сервера базы данных. Использовать базу данных SQLite в dplyr очень просто: достаточно задать путь и отметить, что нужно её создать:

```{r}
my_db <- src_sqlite("my_db.sqlite3", create = T)
```

Главная новая концепция здесь - `src` - коллекция таблиц. Используйте `src_sqlite()`, `src_mysql()`, `src_postgres()` и `src_bigquery()` для соединения с разными базами данных, поддерживаемыми в dplyr.

`my_db` в настоящий момент не содержит данный, поэтому мы загрузим туда данные `flights` с использованием удобной функции `copy_to()`. Это быстрый и "грязный"" способ для того, чтобы поместить данные в базу данных, но он не подходит для очень больших наборов данных, поскольку все данные должны проходить через R.

```{r}
library(nycflights13)
flights_sqlite <- copy_to(my_db, flights, temporary = FALSE, 
            indexes = list(c("year", "month", "day"), "carrier", "tailnum"))
```

Как вы можете видеть, операция `copy_to()` имеет дополнительный аргумент, который позволяет вам задавать индексы для таблицы. Здесь мы создали индексы, которые позволят нам быстро преобразовывать данные по дням, перевозчикам и самолетам. `copy_to()` также выполняет команду SQL `ANALYZE`: это гарантирует, что база данных имеет актуальную статистику таблицу и может выбрать соответствующие средства оптимизации запросов.

Для этого набора данных есть встроенная функция `src`, которая будет кэшировать `flights` в стандартное расположение:

```{r}
flights_sqlite_copy <- tbl(nycflights13_sqlite(), "flights")
flights_sqlite_copy
```

Вы также можете создать `tbl` с помощью SQL:

```{r}
tbl(my_db, sql("SELECT * FROM flights"))
```

## Основные глаголы

Удаленные источники данных используют те же самые 5 глаголов, что и локальные:

```{r}
select(flights_sqlite, year:day, dep_delay, arr_delay)
filter(flights_sqlite, dep_delay > 240)
arrange(flights_sqlite, year, month, day)
mutate(flights_sqlite, speed = air_time / distance)
summarise(flights_sqlite, delay = mean(dep_time))
```

Самое главное отличие в том, что выражения в `select()`, `filter()`, `arrange()`, `mutate()` и `summarise()` транслируются в SQL, так что они могут выполняться на базе данных. Эта трансляция является почти идеальной для наиболее распространенных операций, но существуют некоторые ограничения, о которых вы узнаете чуть позже.

## Ленивость

При работе с базами данных dplyr старается быть настолько "ленивым"", насколько это возможно, двумя способами:

* Никогда не возвращает данные в R, пока вы явно не попросите об этом.

* Это задерживает выполнение любой работы до последней минуты, собирая вместе всё, что вы хотите сделать, и осуществляя запрос к базе данных в один шаг.

Например, возьмем следующий фрагмент кода:

```{r}
c1 <- filter(flights_sqlite, year == 2013, month == 1, day == 1)
c2 <- select(c1, year, month, day, carrier, dep_delay, air_time, distance)
c3 <- mutate(c2, speed = distance / air_time * 60)
c4 <- arrange(c3, year, month, day, carrier)
```

Удивительно, но эта последовательность операций на самом деле никогда не обращается к базе данных - до тех пор, пока вы не запросите данные (например, напечатав `c4`). Тогда dplyr создасть код SQL и запросит результаты из базы данных, и даже здесь будет возвращено только 10 строк.

```{r}
c4
```

Для извлечения всех результатов используйте функцию `collect()`, которая возвращает `tbl_df()`:

```{r}
collect(c4)
```

Вы можете видеть запрос, сгенерированный dplyr, в компоненте `query` объекта:

```{r}
c4$query
```

Вы также можете задать базе данных, как она будет выполнять запрос, при помощи `explain()`. Вывод для SQLite более детально описан на [сайте SQLite](http://www.sqlite.org/eqp.html); это полезно, если вы пытаетесь выяснить, какие индексы используются.

```{r}
explain(c4)
```

### Принудительные вычисления

Есть три способа принудительных вычислений запроса:

* `collect()` выполняет запрос и возвращает результаты в R.

* `compute()` выполняет запрос и сохраняет результаты во временной таблице в базе данных.

* `collapse()` превращает запрос в табличное выражение.

Вероятно, вы будете использовать `collect()`: как только вы в интерактивном режиме дошли до правильного набора операций, используйте `collect()` для извлечения данный в локальный `tbl_df()`. При наличии знаний SQL вы можете использовать `compute()` и `collapse()` для оптимизации производительности.


### Вопросы производительности

dplyr пытается предотвратить случайное выполнение дорогостоящих операций запроса:

* `nrow()` всегда NA: в общем, нет никакого способа определить, сколько строк вернёт запрос, без выполнения самого запроса.

* Печать таблицы запускает запрос, нужный только для получения первых 10 строк.

* Вы не можете использовать `tail()` для таблиц базы данных: нельзя найти последние строки без выполнения запроса целиком.

## Трансляция в SQL

При выполнении простых математических операций в форме, которую вы обычно используете при фильтрации, трансформации и обобщении, можно относительно просто перевести код R в SQL (или даже на любой язык программирования).

Для эксперимента с переводом, используйте `translate_sql()`. Следующие примеры показывают некоторые основные различия между R и SQL.

```{r}
# В SQLite имена переменных экранируются двойными кавычками
translate_sql(x)
# Строки экранируются одинарными кавычками
translate_sql("x")

# Многие функции имеют слегка отличающиеся имена
translate_sql(x == 1 && (y < 2 || z > 3))
translate_sql(x ^ 2 < 10)
translate_sql(x %% 2 == 10)

# R и SQL имеют разные значения по умолчания для целых и вещественных чисел.
# В R, 1 - вещественное, 1L - целое
# В SQL, 1 - целое, 1.0 - вещественное
translate_sql(1)
translate_sql(1L)
```

dplyr знает, как конвертировать в SQL следующией функции R:

* основные математические операторы: `+`, `-`, `*`, `/`, `%%`, `^`

* математические функции: `abs`, `acos`, `acosh`, `asin`, `asinh`, `atan`, `atan2`, `atanh`, `ceiling`, `cos`, `cosh`, `cot`, `coth`, `exp`, `floor`, `log`, `log10`, `round`, `sign`, `sin`, `sinh`, `sqrt`, `tan`, `tanh`

* логические сравнение: `<`, `<=`, `!=`, `>=`, `>`, `==`, `%in%`
    
* булевы операции: `&`, `&&`, `|`, `||`, `!`, `xor`

* основные агрегирующие функции: `mean`, `sum`, `min`, `max`, `sd`, `var`


Основные методы, лежащие в основе реализации `translate_sql()` описаны в [книге Advanced R](http://adv-r.had.co.nz/dsl.html). `translate_sql()` построен поверх синтаксического движка R и был тщательно разработан, чтобы генерировать правильный код SQL. Он также защищает вас от атак типа SQL-инъекций путем правильного экранирования строк и имен переменных, как того требует база данный, к которой вы реализуете соединение.

Невозможно обеспечить идеальную трансляцию, поскольку базы данных не имеют всех функций языка R. Целью dplyr является обеспечение смысловой трансляции: перевести, что вы имеете ввиду, без точных подробностей. Даже если функции существуют и в базах данных, и в R, вам не следует ожидать в точности одинаковых результатов; приоритеты программистов баз данных отличаются от приоритетов разработчиков R. 

Например, в R функция `mean()` делает два прохода по данным с целью повышения вычислительной точности ценой двукратного замедления. `mean()` также предоставляет опцию `trim` для расчёта усечённых средних, чего не предоставляют базы данных. Базы данных автоматически отбрасывают NULLs (их эквивалент пропущенных значений), в то время как в R вы должны об этом попросить. Это означает, что простые вызовы типа `mean(x)` будут транслироваться точно, но более сложные, такие как ` mean(x, trim = 0.5, na.rm = TRUE)`, вызовут ошибку:

```{r, eval=FALSE}
translate_sql(mean(x, trim = T))
# Error: Invalid number of args to SQL AVG. Expecting 1
```

Любые функции, которые dplyr не умеет конвертировать, остаются "как есть" - это означает, что можно использовать любые другие функции, поддерживаемые базой данных. Вот несколько примеров, как это будеи работать с [SQLite](http://www.sqlite.org/lang_corefunc.html):

```{r}
translate_sql(glob(x, y))
translate_sql(x %like% "ab*")
```

## Группировка

SQLite не хватает "оконных" функций, которые нужны для сгруппированного преобразования и фильтрации. Это означает, что единственной полезной операцией для группировки таблиц sqlite является `summarise()`. Сгруппированные итоги из введения транслируются правильно - единственное различие состоит в том, что базы данных всегда отбрасывают NULLs (их эквивалент пропущенных значений), поэтому не используется `na.rm = TRUE`.

```{r}
by_tailnum <- group_by(flights_sqlite, tailnum)
delay <- summarise(by_tailnum,
  count = n(),
  dist = mean(distance),
  delay = mean(arr_delay)
)
delay <- filter(delay, count > 20, dist < 2000)
delay_local <- collect(delay)
```

Другие базы данных поддерживают "оконные"" функции, и вы можете узнать о них в соответствующей виньетке. Иногда можно имитировать сгруппированные фильтры и трансформации с использованием автообъединения, где вы объединяете исходную таблицы со сгруппированной версией, но эта тема выходит за рамки данного введения.

## Другие базы данных

Использование других баз данных вместо SQLite работает аналогично, общий рабочий процесс такой же, независимо от того, к какой базе данных вы подключаетесь. В следующих разделах перейдем к более подробной информации об особенностях каждой базы данных. Все эти базы данных следуют модели "клиент-сервер" - кроме вашего компьютер, который подключается к базе данных, есть другой компьютер, который на самом деле осуществляет обработку (сервером может выступать ваш компьютер, но, как правило, это не так). Получение настроек этих баз данных выходит за рамки данной статьи, но есть много учебников, доступных в Интернете.

### Postgresql

`src_postgres()` имеет пять аргументов: `dbname`, `host`, `port`, `user` и `password`. Если вы используете локальную базу данных postgresql с настройками по умолчанию, вам потребуется только `dbname`, но в большинстве случаев нужны все аргументы.  dplyr использует пакет RPostgreSQL для соединения с базой данных postgres. Это означает, что сейчас вы не можете подключиться к удаленной базе данных, требующей соединения SSL (например, Heroku).

Например, следующий фрагмент кода позволяет мне подключиться к локальной базе данных postgresql, содержащей копию данных `flights`:

```{r}
if (has_lahman("postgres")) {
  flights_postgres <- tbl(src_postgres("nycflights13"), "flights")
}
```

Postgres - значительно более мощная база данных, чем SQLite. Она имеет

*  более широкий спектр [встроенных функций](http://www.postgresql.org/docs/9.3/static/functions.html)

* поддержку [оконных функций](http://www.postgresql.org/docs/9.3/static/tutorial-window.html), что позволяет работать сгруппированным преобразованиям и выделению поднаборов

Следующие примеры показывают сгруппированные фильтры и преобразования, возможные с PostgreSQL. Код SQL, который генерируется из сгруппированных фильтров, является довольно сложным, потому что вы не можете использовать применять фильтры непосредственно на оконных функциях; вместо этого они должны уйти как подзапрос.

```{r}
if (has_lahman("postgres")) {
  daily <- group_by(flights_postgres, year, month, day)

  # Найти наибольшую и наименьшую задержку рейса за каждый день
  bestworst <- daily %>% 
    select(flight, arr_delay) %>% 
    filter(arr_delay == min(arr_delay) || arr_delay == max(arr_delay))
  bestworst$query

  # Позиция каждого полета в пределах дня
  ranked <- daily %>% 
    select(arr_delay) %>% 
    mutate(rank = rank(desc(arr_delay)))
  ranked$query
}
```

### MySQL и MariaDB

Вы можете подключиться к MySQL и MariaDB (форк MySQL) используя `src_mysql()` через пакет [RMySQLe](https://github.com/rstats-db/RMySQL). Подобно PostgreSQL, вам потребуется `dbname`, `username`, `password`, `host` и `port`.

С точки зрения функциональности, MySQL лежит где-то между SQLite и PostgreSQL. Она обеспечивает более широкий спектр [встроенных функций](http://dev.mysql.com/doc/refman/5.0/en/functions.html), но не поддерживает "оконные" функции (поэтому вы не сможете выполнять сгруппированные преобразования и фильтрацию).

### Bigquery

Bigquery является сервером баз данных, предоставляемым google. Для подключения вы должны предоставить ваши `project`, `dataset` и, возможно, проект для `billing` (если биллинг для `project` не включен). После создания src ваш веб-браузер откроется и попросит вас пройти аутентификацию. Ваши учетные данные хранятся в локальном кэше, так что вы должны будете сделать это только один раз.

Bigquery поддерживает только один оператор SQL: [SELECT](https://cloud.google.com/bigquery/query-reference). К счастью, это все, что вам нужно для анализа данных, и с помощью SELECT bigquery предоставляет полный охват на том же уровне, что и postgresql.

## Выбор базы данных

Если у вас еще нет базы данных, то вот несколько советов из моего опыта создания и использования их всех. SQLite является самым простым вариантом, чтобы начать, но отсутствие "оконных"" функций делает его ограниченным для анализа данных. PostgreSQL не намного сложнее в использовании, и имеет широкий диапазон встроенных функций. Не связывайтесь с MySQL/MariaDB: их настройки сложны и документация плоха. Google bigquery может подойти, если у вас очень большие объемы данных, или вы готовы платить кому-то (небольшое количество) денег, чтобы о вашей базе данных позаботились.

